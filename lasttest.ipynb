{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import minibatch, compounding\n",
    "df =(pd.read_csv(\"/Users/aliku/Projects/projects/this-label.csv\", usecols=['Title']))\n",
    "titles=[_ for _ in df['Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['500 gr kuşbaşı doğranmış et 1 su bardağı sıcak su 4 yemek kaşığı sıvı yağ 2 su bardağı pirinç 2 adet patates 1 yemek kaşığı tereyağı Tuz',\n",
       " 'Üç bardak su ile deneyin ben öyle yapıyorum yağ miktarınıda artırdım çok güzel oldu  ',\n",
       " 'İnce yemeklik doğranmış soğanı sıvı yağ ile pişirme tencerenize alın.Kavurun. ',\n",
       " \"Konya Sanayi Odası Başkanı Memiş Kütükcü ise, ASELSAN'ın Konya'ya yapacağı yatırım ilk kez 2018 yılının Haziran ayında kamuoyuyla paylaşıldığını belirtti. \",\n",
       " 'Pirinçler ilave edilerek, 2-3 dk daha kavrulur. ',\n",
       " 'Derin bir tencerede kuş başı doğranmış etlerimizi suyunu salıp çekene kadar yüksek ateşte kavuralım. Etlerinizi kavururken ara ara karıştırmayı unutmayın.',\n",
       " 'Daha sonra diğer malzemelerin hepsini atıp kaşıkla bir güzel karıştırıyoruz. Rengi ve baharatları iyice bulgura dağılana kadar. ',\n",
       " 'tarif için teşekkürler.bu arada bilginiz olsun saksukaya genelde soğuk meze ustalari soğan koymazlar tadı ağırlaştırır diye.  ',\n",
       " 'Yemek kaynadıktan sonra köfteleri ilave ederek, tuz ve baharatını ilave edelim. ',\n",
       " 'Kıvamı koyu olursa su miktarını artırın. ',\n",
       " 'Haşladığınız tavukların suyundan 1 litre tepsiye dökün. Pilavın üstünü hafifçe geçecek kadar dökmeniz de yeterli olacaktır.Tavukların aralarına gelecek şekilde tereyağını serpiştirin.\\n\\n',\n",
       " 'Karıştırılarak ocaktan alınır. Son olarak ince doğranmış maydanoz ve taze naneler eklenir ve güzelce karıştırılır. ',\n",
       " 'Demlenmesi için mutfak bezinizle bohçalayarak 15 dk bekletin. ',\n",
       " '5 dakika sonra tatlımız hazır afiyet olsun. ',\n",
       " 'Hazırladığınız topları bir serrvis kasesine koyun.\\n\\n',\n",
       " 'ek gıdalara 6 aylıkken başlanıyor zaten bi yüzden karışık yerine daha az ve belirgin Malz. çorbalar verilmeli.cocuk Dr .yada sağlık kuruluşlarında bulunan bebek hem. Bu konularda Yard. oluyorlar.bence bebeklerin ilk yemekleri daha sade olmalilar  ',\n",
       " '2016 yılında yüzde 36 büyüyen şirket Capital500 sıralamasında 15 basamak sıçradı',\n",
       " 'Açtığınız çukurun içerisine önce bezelyelerin yarısını ve haşlanmış uzun şeritler halinde kesilmiş havuçları yerleştirin.\\n\\n',\n",
       " '1 adet patlıcan 1 adet kabak 1 adet kapya biber 2 adet patates 5-6 adet yeşil biber 4 yemek kaşığı zeytin yağ 1 çay kaşığı tuz',\n",
       " 'Tüm malzemeler derince bir kapta 10 dakika boyunca iyice yoğurulur. Tezgah üzerine serilen streç filme tüm malzemeler yerleştirilir ve rulo yapılır.\\n\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import datetime as dt\n",
    "random.choices(titles,k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp=spacy.blank(\"tr\")\n",
    "ner=nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner,last=True)\n",
    "ner=nlp.get_pipe(\"ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seker_pattern = [{'LOWER': 'şeker'}]\n",
    "sarımsak_pattern =           [{'LOWER': 'sarımsak'}]\n",
    "sarımsak_pattern =           [{'LOWER': 'kimyon'}]\n",
    "yumurta_pattern =           [{'LOWER': 'yumurta'}]\n",
    "tuz_pattern =           [{'LOWER': 'tuz'}]\n",
    "havuç_pattern =           [{'LOWER': 'havuç'}]\n",
    "et_pattern =           [{'LOWER': 'et'}]\n",
    "tavuk_pattern =           [{'LOWER': 'tavuk'}]\n",
    "patates_pattern =           [{'LOWER': 'patates'}]\n",
    "zeytin_pattern =           [{'LOWER': 'zeytin'}]\n",
    "yoğurt_pattern =           [{'LOWER': 'yoğurt'}]\n",
    "süt_pattern =           [{'LOWER': 'süt'}]\n",
    "un_pattern =           [{'LOWER': 'un'}]\n",
    "peynir_pattern =           [{'LOWER': 'peynir'}]\n",
    "toz_biber_pattern =           [{'LOWER': 'toz biber'}]\n",
    "biber_pattern =           [{'LOWER': 'biber'}]\n",
    "kapya_biber_pattern =           [{'LOWER': 'kapya biber'}]\n",
    "tahin_pattern =           [{'LOWER': 'tahin'}]\n",
    "limon_pattern =           [{'LOWER': 'limon'}]\n",
    "zeytinyağı_pattern =           [{'LOWER':'zeytinyağı'}]\n",
    "maydonoz_pattern =           [{'LOWER': 'maydonoz'}]\n",
    "domates_pattern =           [{'LOWER': 'domates'}]\n",
    "salatalık_pattern =           [{'LOWER': 'salatalık'}]\n",
    "karabiber_pattern =           [{'LOWER': 'karabiber'}]\n",
    "pulbiber_pattern =           [{'LOWER': 'pulbiber'}]\n",
    "kekik_pattern =           [{'LOWER': 'kekik'}]\n",
    "kiyma_pattern =           [{'LOWER': 'kıyma'}]\n",
    "Tereyagi_pattern =           [{'LOWER': 'tereyağı'}]\n",
    "tozseker_pattern =           [{'LOWER': 'toz şeker'}]\n",
    "tarcin_pattern =           [{'LOWER': 'tarçın'}]\n",
    "nane_pattern =           [{'LOWER': 'nane'}]\n",
    "kusuzumu_pattern =           [{'LOWER': 'kuş üzümü'}]\n",
    "yenibahar_pattern =           [{'LOWER': 'yenibahar'}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher=Matcher(nlp.vocab)\n",
    "matcher.add(\"Malzeme\",None,seker_pattern,sarımsak_pattern,sarımsak_pattern,yumurta_pattern,tuz_pattern,havuç_pattern,et_pattern,tavuk_pattern,patates_pattern,zeytin_pattern,yoğurt_pattern,süt_pattern,un_pattern,peynir_pattern,toz_biber_pattern,biber_pattern,kapya_biber_pattern,tahin_pattern,limon_pattern,zeytinyağı_pattern,maydonoz_pattern,domates_pattern,salatalık_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train_data(doc):\n",
    "    detections=[(doc[start:end].start_char,doc[start:end].end_char,'MALZEME') for idx, start, end in matcher(doc)]\n",
    "    return (doc.text,{'entities':detections})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aliku\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\language.py:635: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  proc.begin_training(\n"
     ]
    }
   ],
   "source": [
    "df =(pd.read_csv(\"/Users/aliku/Projects/projects/this-label.csv\", usecols=['label','Title']))\n",
    "titles=df.loc[lambda d: d['label']==1]['Title']\n",
    "optimizer=nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bulgur köfteleri piştikçe suyun üstüne çıkacaklardır. Pişen köfteleri bir kevgirle alın ve sosun içine atın.Bir dakika kadar da bu şekilde pişirdikten sonra bir servis tabağına alın.Üstüne sarımsaklı yoğurt gezdirin, toz biberle süsleyip servis edin. Afiyetler olsun!\\n\\n',\n",
       "  {'entities': [(200, 206, 'MALZEME')]}),\n",
       " ('Tatlının şerbeti için; 1,5 su bardağı su, 1,5 su bardağı şeker ve 1,5 su bardağı sütü küçük bir sos tenceresine alın. Karıştırdıktan sonra kısık ateşte kaynamaya bırakın.\\n\\n',\n",
       "  {'entities': [(57, 62, 'MALZEME')]}),\n",
       " ('Un helvası gibi oldu', {'entities': [(0, 2, 'MALZEME')]})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA=[parse_train_data(d) for d in nlp.pipe(titles) if len(matcher(d))==1]\n",
    "TRAIN_DATA[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_nlp(train_data):\n",
    "    nlp = spacy.blank(\"tr\")\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0 - 2020-12-29 16:00:34.815184 {'ner': 143.1582765508665}\n",
      "Losses at iteration 1 - 2020-12-29 16:00:38.112604 {'ner': 2.7645925134672673}\n",
      "Losses at iteration 2 - 2020-12-29 16:00:41.502480 {'ner': 2.2315087385418018}\n",
      "Losses at iteration 3 - 2020-12-29 16:00:44.803904 {'ner': 0.0001040541588457864}\n",
      "Losses at iteration 4 - 2020-12-29 16:00:48.003962 {'ner': 3.2638384928284603e-08}\n",
      "Losses at iteration 5 - 2020-12-29 16:00:51.504753 {'ner': 1.8549108443873042e-08}\n",
      "Losses at iteration 6 - 2020-12-29 16:00:54.852511 {'ner': 1.3199770782881382e-08}\n",
      "Losses at iteration 7 - 2020-12-29 16:00:58.566350 {'ner': 9.75692854333419e-09}\n",
      "Losses at iteration 8 - 2020-12-29 16:01:02.246180 {'ner': 7.313340960906435e-09}\n",
      "Losses at iteration 9 - 2020-12-29 16:01:06.074661 {'ner': 5.086953754588763e-09}\n",
      "Losses at iteration 10 - 2020-12-29 16:01:10.520958 {'ner': 3.759385642469869e-09}\n",
      "Losses at iteration 11 - 2020-12-29 16:01:14.785928 {'ner': 2.9819275201848546e-09}\n",
      "Losses at iteration 12 - 2020-12-29 16:01:19.127232 {'ner': 2.2506953958226307e-09}\n",
      "Losses at iteration 13 - 2020-12-29 16:01:23.683261 {'ner': 1.802804878488262e-09}\n",
      "Losses at iteration 14 - 2020-12-29 16:01:27.862206 {'ner': 1.4924438837464536e-09}\n",
      "Losses at iteration 15 - 2020-12-29 16:01:32.534261 {'ner': 1.190158290567332e-09}\n",
      "Losses at iteration 16 - 2020-12-29 16:01:37.016949 {'ner': 1.0031566366825396e-09}\n",
      "Losses at iteration 17 - 2020-12-29 16:01:41.355250 {'ner': 8.3712316240992e-10}\n",
      "Losses at iteration 18 - 2020-12-29 16:01:45.530990 {'ner': 7.08643194341901e-10}\n",
      "Losses at iteration 19 - 2020-12-29 16:01:50.092020 {'ner': 5.966440792855757e-10}\n",
      "Losses at iteration 20 - 2020-12-29 16:01:54.561030 {'ner': 5.115797727033119e-10}\n",
      "Losses at iteration 21 - 2020-12-29 16:01:58.751977 {'ner': 4.451822829914731e-10}\n",
      "Losses at iteration 22 - 2020-12-29 16:02:03.378287 {'ner': 3.8325627099697107e-10}\n",
      "Losses at iteration 23 - 2020-12-29 16:02:07.631951 {'ner': 3.2908191264146335e-10}\n",
      "Losses at iteration 24 - 2020-12-29 16:02:12.162957 {'ner': 2.9046325272769094e-10}\n",
      "Losses at iteration 25 - 2020-12-29 16:02:16.578444 {'ner': 2.521397829746483e-10}\n",
      "Losses at iteration 26 - 2020-12-29 16:02:20.848409 {'ner': 2.2030250849112684e-10}\n",
      "Losses at iteration 27 - 2020-12-29 16:02:25.123375 {'ner': 1.9901358080633754e-10}\n",
      "Losses at iteration 28 - 2020-12-29 16:02:29.448352 {'ner': 1.7504905761326534e-10}\n",
      "Losses at iteration 29 - 2020-12-29 16:02:33.842345 {'ner': 1.547379293758752e-10}\n",
      "Losses at iteration 30 - 2020-12-29 16:02:38.376397 {'ner': 1.3626081836337894e-10}\n",
      "Losses at iteration 31 - 2020-12-29 16:02:42.477390 {'ner': 1.209834626392546e-10}\n",
      "Losses at iteration 32 - 2020-12-29 16:02:46.984427 {'ner': 1.0833902349389227e-10}\n",
      "Losses at iteration 33 - 2020-12-29 16:02:51.655482 {'ner': 9.642226205787438e-11}\n",
      "Losses at iteration 34 - 2020-12-29 16:02:55.897441 {'ner': 8.698610286340564e-11}\n",
      "Losses at iteration 35 - 2020-12-29 16:03:00.128396 {'ner': 7.932176253789937e-11}\n",
      "Losses at iteration 36 - 2020-12-29 16:03:04.832744 {'ner': 7.165418985017418e-11}\n",
      "Losses at iteration 37 - 2020-12-29 16:03:09.477992 {'ner': 6.611277767747372e-11}\n",
      "Losses at iteration 38 - 2020-12-29 16:03:13.686986 {'ner': 5.990940990555461e-11}\n",
      "Losses at iteration 39 - 2020-12-29 16:03:17.765037 {'ner': 5.470796422608357e-11}\n",
      "Losses at iteration 40 - 2020-12-29 16:03:21.952984 {'ner': 4.914488211664646e-11}\n",
      "Losses at iteration 41 - 2020-12-29 16:03:26.178938 {'ner': 4.4802915454805064e-11}\n",
      "Losses at iteration 42 - 2020-12-29 16:03:31.016509 {'ner': 4.105978756660004e-11}\n",
      "Losses at iteration 43 - 2020-12-29 16:03:35.400851 {'ner': 3.798611123843288e-11}\n",
      "Losses at iteration 44 - 2020-12-29 16:03:39.653997 {'ner': 3.506513192217156e-11}\n",
      "Losses at iteration 45 - 2020-12-29 16:03:44.133445 {'ner': 3.1872357078395796e-11}\n",
      "Losses at iteration 46 - 2020-12-29 16:03:48.312390 {'ner': 2.9864760959294496e-11}\n",
      "Losses at iteration 47 - 2020-12-29 16:03:52.839414 {'ner': 2.727115365204837e-11}\n",
      "Losses at iteration 48 - 2020-12-29 16:03:57.212400 {'ner': 2.518416628061061e-11}\n",
      "Losses at iteration 49 - 2020-12-29 16:04:01.311326 {'ner': 2.3169708377173766e-11}\n",
      "Losses at iteration 50 - 2020-12-29 16:04:05.970438 {'ner': 2.1536253873694668e-11}\n"
     ]
    }
   ],
   "source": [
    "nlp = create_blank_nlp(TRAIN_DATA)\n",
    "optimizer = nlp.begin_training()  \n",
    "for i in range(100):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        nlp.update([text], [annotations], sgd=optimizer, losses=losses)\n",
    "    print(f\"Losses at iteration {i} - {dt.datetime.now()}\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(\"süt, yumurta ve un ile yapılan krepler çok güzel oluyor.\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(\"tavuk filetoları güzelce açın, tuz ve karabiber ile her iki tarafını çeşnilendirin.\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"/model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
